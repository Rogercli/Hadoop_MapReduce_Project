[root@sandbox-hdp hdfs]# sh run_script.sh 
Running mapreduce one
21/11/19 08:30:38 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [mapper_one.py, reducer_one.py] [/usr/hdp/3.0.1.0-187/hadoop-mapreduce/hadoop-streaming-3.1.1.3.0.1.0-187.jar] /tmp/streamjob2963068971085520377.jar tmpDir=null
21/11/19 08:30:38 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:30:38 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:30:38 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:30:38 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:30:38 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://sandbox-hdp.hortonworks.com:8020/user/root/output/accident_type already exists
Streaming Command Failed!
Running mapreduce two
21/11/19 08:30:39 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [mapper_two.py, reducer_two.py] [/usr/hdp/3.0.1.0-187/hadoop-mapreduce/hadoop-streaming-3.1.1.3.0.1.0-187.jar] /tmp/streamjob2850383192041193035.jar tmpDir=null
21/11/19 08:30:40 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:30:40 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:30:40 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:30:40 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:30:40 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://sandbox-hdp.hortonworks.com:8020/user/root/output/accident_count already exists
Streaming Command Failed!
[root@sandbox-hdp hdfs]# hdfs dfs -rmdir output/accident_count
[root@sandbox-hdp hdfs]# hdfs dfs -rmdir output/accident_type
^[[A^[[A[root@sandbox-hdp hdfs]# 
[root@sandbox-hdp hdfs]# hdfs dfs -ls output
[root@sandbox-hdp hdfs]# sh run_script.sh 
Running mapreduce one
21/11/19 08:31:36 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [mapper_one.py, reducer_one.py] [/usr/hdp/3.0.1.0-187/hadoop-mapreduce/hadoop-streaming-3.1.1.3.0.1.0-187.jar] /tmp/streamjob5709495651055589510.jar tmpDir=null
21/11/19 08:31:37 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:31:37 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:31:37 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:31:37 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:31:37 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/root/.staging/job_1637304322871_0006
21/11/19 08:31:37 INFO mapred.FileInputFormat: Total input files to process : 1
21/11/19 08:31:37 INFO mapreduce.JobSubmitter: number of splits:2
21/11/19 08:31:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1637304322871_0006
21/11/19 08:31:37 INFO mapreduce.JobSubmitter: Executing with tokens: []
21/11/19 08:31:37 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.1.0-187/0/resource-types.xml
21/11/19 08:31:37 INFO impl.YarnClientImpl: Submitted application application_1637304322871_0006
21/11/19 08:31:37 INFO mapreduce.Job: The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1637304322871_0006/
21/11/19 08:31:37 INFO mapreduce.Job: Running job: job_1637304322871_0006
21/11/19 08:31:42 INFO mapreduce.Job: Job job_1637304322871_0006 running in uber mode : false
21/11/19 08:31:42 INFO mapreduce.Job:  map 0% reduce 0%
21/11/19 08:31:58 INFO mapreduce.Job:  map 100% reduce 0%
21/11/19 08:32:01 INFO mapreduce.Job:  map 100% reduce 100%
21/11/19 08:32:01 INFO mapreduce.Job: Job job_1637304322871_0006 completed successfully
21/11/19 08:32:01 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=606
		FILE: Number of bytes written=716084
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1722
		HDFS: Number of bytes written=174
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=119180
		Total time spent by all reduces in occupied slots (ms)=6200
		Total time spent by all map tasks (ms)=29795
		Total time spent by all reduce tasks (ms)=1550
		Total vcore-milliseconds taken by all map tasks=29795
		Total vcore-milliseconds taken by all reduce tasks=1550
		Total megabyte-milliseconds taken by all map tasks=30510080
		Total megabyte-milliseconds taken by all reduce tasks=1587200
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=568
		Map output materialized bytes=612
		Input split bytes=232
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=612
		Reduce input records=16
		Reduce output records=4
		Spilled Records=32
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=90
		CPU time spent (ms)=2670
		Physical memory (bytes) snapshot=1768660992
		Virtual memory (bytes) snapshot=8475422720
		Total committed heap usage (bytes)=1598029824
		Peak Map Physical memory (bytes)=785170432
		Peak Map Virtual memory (bytes)=2909896704
		Peak Reduce Physical memory (bytes)=206766080
		Peak Reduce Virtual memory (bytes)=2695262208
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1490
	File Output Format Counters 
		Bytes Written=174
21/11/19 08:32:01 INFO streaming.StreamJob: Output directory: output/accident_type
Running mapreduce two
21/11/19 08:32:02 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [mapper_two.py, reducer_two.py] [/usr/hdp/3.0.1.0-187/hadoop-mapreduce/hadoop-streaming-3.1.1.3.0.1.0-187.jar] /tmp/streamjob6622759630291695634.jar tmpDir=null
21/11/19 08:32:03 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:32:03 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:32:03 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/11/19 08:32:03 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/11/19 08:32:03 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/root/.staging/job_1637304322871_0007
21/11/19 08:32:03 INFO mapred.FileInputFormat: Total input files to process : 1
21/11/19 08:32:03 INFO mapreduce.JobSubmitter: number of splits:2
21/11/19 08:32:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1637304322871_0007
21/11/19 08:32:03 INFO mapreduce.JobSubmitter: Executing with tokens: []
21/11/19 08:32:03 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.1.0-187/0/resource-types.xml
21/11/19 08:32:04 INFO impl.YarnClientImpl: Submitted application application_1637304322871_0007
21/11/19 08:32:04 INFO mapreduce.Job: The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1637304322871_0007/
21/11/19 08:32:04 INFO mapreduce.Job: Running job: job_1637304322871_0007
21/11/19 08:32:08 INFO mapreduce.Job: Job job_1637304322871_0007 running in uber mode : false
21/11/19 08:32:08 INFO mapreduce.Job:  map 0% reduce 0%
21/11/19 08:32:12 INFO mapreduce.Job:  map 100% reduce 0%
21/11/19 08:32:15 INFO mapreduce.Job:  map 100% reduce 100%
21/11/19 08:32:16 INFO mapreduce.Job: Job job_1637304322871_0007 completed successfully
21/11/19 08:32:16 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=72
		FILE: Number of bytes written=715034
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=527
		HDFS: Number of bytes written=43
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=13084
		Total time spent by all reduces in occupied slots (ms)=6144
		Total time spent by all map tasks (ms)=3271
		Total time spent by all reduce tasks (ms)=1536
		Total vcore-milliseconds taken by all map tasks=3271
		Total vcore-milliseconds taken by all reduce tasks=1536
		Total megabyte-milliseconds taken by all map tasks=3349504
		Total megabyte-milliseconds taken by all reduce tasks=1572864
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=58
		Map output materialized bytes=78
		Input split bytes=266
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=78
		Reduce input records=4
		Reduce output records=3
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=106
		CPU time spent (ms)=1830
		Physical memory (bytes) snapshot=1799639040
		Virtual memory (bytes) snapshot=8477675520
		Total committed heap usage (bytes)=1618477056
		Peak Map Physical memory (bytes)=795574272
		Peak Map Virtual memory (bytes)=2891825152
		Peak Reduce Physical memory (bytes)=211832832
		Peak Reduce Virtual memory (bytes)=2698440704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=261
	File Output Format Counters 
		Bytes Written=43
21/11/19 08:32:16 INFO streaming.StreamJob: Output directory: output/accident_count
